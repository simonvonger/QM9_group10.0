{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu will be used for training the PaiNN model\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "[enforce fail at alloc_cpu.cpp:80] data. DefaultCPUAllocator: not enough memory: you tried to allocate 278031538176 bytes.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\vonge\\Deep_Learning\\QM9_group10\\Main.ipynb Cell 1\u001b[0m line \u001b[0;36m3\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/vonge/Deep_Learning/QM9_group10/Main.ipynb#W0sZmlsZQ%3D%3D?line=29'>30</a>\u001b[0m         trainer\u001b[39m.\u001b[39mplot_data()\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/vonge/Deep_Learning/QM9_group10/Main.ipynb#W0sZmlsZQ%3D%3D?line=31'>32</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39m__name__\u001b[39m\u001b[39m==\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m__main__\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/vonge/Deep_Learning/QM9_group10/Main.ipynb#W0sZmlsZQ%3D%3D?line=32'>33</a>\u001b[0m     training()\n",
      "\u001b[1;32mc:\\Users\\vonge\\Deep_Learning\\QM9_group10\\Main.ipynb Cell 1\u001b[0m line \u001b[0;36m2\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/vonge/Deep_Learning/QM9_group10/Main.ipynb#W0sZmlsZQ%3D%3D?line=18'>19</a>\u001b[0m scheduler \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39moptim\u001b[39m.\u001b[39mlr_scheduler\u001b[39m.\u001b[39mReduceLROnPlateau(optimizer, \u001b[39m'\u001b[39m\u001b[39mmin\u001b[39m\u001b[39m'\u001b[39m, factor\u001b[39m=\u001b[39m\u001b[39m0.5\u001b[39m, patience \u001b[39m=\u001b[39m \u001b[39m5\u001b[39m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/vonge/Deep_Learning/QM9_group10/Main.ipynb#W0sZmlsZQ%3D%3D?line=19'>20</a>\u001b[0m trainer \u001b[39m=\u001b[39m Trainer(\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/vonge/Deep_Learning/QM9_group10/Main.ipynb#W0sZmlsZQ%3D%3D?line=20'>21</a>\u001b[0m     model\u001b[39m=\u001b[39mmodel,\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/vonge/Deep_Learning/QM9_group10/Main.ipynb#W0sZmlsZQ%3D%3D?line=21'>22</a>\u001b[0m     loss\u001b[39m=\u001b[39mmse,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/vonge/Deep_Learning/QM9_group10/Main.ipynb#W0sZmlsZQ%3D%3D?line=26'>27</a>\u001b[0m     device\u001b[39m=\u001b[39mdevice\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/vonge/Deep_Learning/QM9_group10/Main.ipynb#W0sZmlsZQ%3D%3D?line=27'>28</a>\u001b[0m )\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/vonge/Deep_Learning/QM9_group10/Main.ipynb#W0sZmlsZQ%3D%3D?line=28'>29</a>\u001b[0m trainer\u001b[39m.\u001b[39;49m_train(num_epoch \u001b[39m=\u001b[39;49m \u001b[39m3\u001b[39;49m, early_stopping \u001b[39m=\u001b[39;49m \u001b[39m2\u001b[39;49m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/vonge/Deep_Learning/QM9_group10/Main.ipynb#W0sZmlsZQ%3D%3D?line=29'>30</a>\u001b[0m trainer\u001b[39m.\u001b[39mplot_data()\n",
      "File \u001b[1;32mc:\\Users\\vonge\\Deep_Learning\\QM9_group10\\Training.py:95\u001b[0m, in \u001b[0;36mTrainer._train\u001b[1;34m(self, num_epoch, early_stopping, alpha)\u001b[0m\n\u001b[0;32m     93\u001b[0m patience \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n\u001b[0;32m     94\u001b[0m \u001b[39mfor\u001b[39;00m epoch \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(num_epoch):\n\u001b[1;32m---> 95\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_train_epoch()\n\u001b[0;32m     96\u001b[0m     \u001b[39m# Validate at the end of an epoch\u001b[39;00m\n\u001b[0;32m     97\u001b[0m     val_loss \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_eval_model()\n",
      "File \u001b[1;32mc:\\Users\\vonge\\Deep_Learning\\QM9_group10\\Training.py:49\u001b[0m, in \u001b[0;36mTrainer._train_epoch\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     46\u001b[0m targets \u001b[39m=\u001b[39m batch[\u001b[39m\"\u001b[39m\u001b[39mtargets\u001b[39m\u001b[39m\"\u001b[39m][:, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtarget]\u001b[39m.\u001b[39mto(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdevice)\u001b[39m.\u001b[39munsqueeze(dim\u001b[39m=\u001b[39m\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[0;32m     48\u001b[0m \u001b[39m# Backpropagate using the selected loss\u001b[39;00m\n\u001b[1;32m---> 49\u001b[0m outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmodel(batch)\n\u001b[0;32m     50\u001b[0m loss \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mloss(outputs, targets)\n\u001b[0;32m     52\u001b[0m \u001b[39mif\u001b[39;00m i\u001b[39m%\u001b[39m\u001b[39m100\u001b[39m \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n",
      "File \u001b[1;32mc:\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1516\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m-> 1518\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_impl(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[1;32mc:\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1522\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1523\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1524\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1525\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1526\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1527\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m   1529\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m   1530\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\vonge\\Deep_Learning\\QM9_group10\\Model.py:58\u001b[0m, in \u001b[0;36mPaiNN.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m     52\u001b[0m v \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mzeros((unique_atm_mat\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m], \u001b[39m3\u001b[39m, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39membedding_size), \u001b[39m# tidligere navn: v_j\u001b[39;00m\n\u001b[0;32m     53\u001b[0m                           device \u001b[39m=\u001b[39m r_ij\u001b[39m.\u001b[39mdevice,\n\u001b[0;32m     54\u001b[0m                           dtype \u001b[39m=\u001b[39m r_ij\u001b[39m.\u001b[39mdtype\n\u001b[0;32m     55\u001b[0m                           )\u001b[39m.\u001b[39mto(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdevice)\n\u001b[0;32m     57\u001b[0m \u001b[39mfor\u001b[39;00m message_block, update_block \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmessage_blocks, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mupdate_blocks):\n\u001b[1;32m---> 58\u001b[0m     s, v \u001b[39m=\u001b[39m message_block(\n\u001b[0;32m     59\u001b[0m         s \u001b[39m=\u001b[39;49m s,\n\u001b[0;32m     60\u001b[0m         v \u001b[39m=\u001b[39;49m v,\n\u001b[0;32m     61\u001b[0m         edges \u001b[39m=\u001b[39;49m edges,\n\u001b[0;32m     62\u001b[0m         r_ij \u001b[39m=\u001b[39;49m r_ij,\n\u001b[0;32m     63\u001b[0m         r_ij_normalized \u001b[39m=\u001b[39;49m r_ij_normalized\n\u001b[0;32m     64\u001b[0m     )\n\u001b[0;32m     65\u001b[0m     s, v \u001b[39m=\u001b[39m update_block(\n\u001b[0;32m     66\u001b[0m         s \u001b[39m=\u001b[39m s,\n\u001b[0;32m     67\u001b[0m         v \u001b[39m=\u001b[39m v\n\u001b[0;32m     68\u001b[0m     )\n\u001b[0;32m     70\u001b[0m blue_outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mblue_block(s)\n",
      "File \u001b[1;32mc:\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1516\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m-> 1518\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_impl(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[1;32mc:\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1522\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1523\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1524\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1525\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1526\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1527\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m   1529\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m   1530\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\vonge\\Deep_Learning\\QM9_group10\\Model.py:107\u001b[0m, in \u001b[0;36mMessageBlock.forward\u001b[1;34m(self, s, v, edges, r_ij, r_ij_normalized)\u001b[0m\n\u001b[0;32m    105\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, s, v, edges, r_ij, r_ij_normalized):\n\u001b[0;32m    106\u001b[0m     rbf_pass \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrbf_layer(RBF(r_ij, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mr_cut))\n\u001b[1;32m--> 107\u001b[0m     rbf_pass \u001b[39m=\u001b[39m rbf_pass \u001b[39m*\u001b[39;49m fcut(r_ij, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mr_cut)\u001b[39m.\u001b[39;49munsqueeze(\u001b[39m-\u001b[39;49m\u001b[39m1\u001b[39;49m)\n\u001b[0;32m    108\u001b[0m     s_pass \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnet(s)\n\u001b[0;32m    109\u001b[0m     pass_out \u001b[39m=\u001b[39m rbf_pass \u001b[39m*\u001b[39m s_pass[edges[:,\u001b[39m1\u001b[39m]]\n",
      "\u001b[1;31mRuntimeError\u001b[0m: [enforce fail at alloc_cpu.cpp:80] data. DefaultCPUAllocator: not enough memory: you tried to allocate 278031538176 bytes."
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x500 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy\n",
    "from Dataloader import DataLoaderQM9\n",
    "from Model import PaiNN\n",
    "from Training import Trainer\n",
    "from Training import mse\n",
    "\n",
    "\n",
    "def training():\n",
    "        device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        print(f\"{device} will be used for training the PaiNN model\")\n",
    "        model = PaiNN(r_cut=5, \n",
    "                device=device\n",
    "                ).to(device)\n",
    "\n",
    "        train_set = DataLoaderQM9(r_cut=5)\n",
    "        optimizer = torch.optim.Adam(params=model.parameters(), lr = 5e-4, weight_decay = 0.01)\n",
    "        scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', factor=0.5, patience = 5)\n",
    "        trainer = Trainer(\n",
    "            model=model,\n",
    "            loss=mse,\n",
    "            target=2,\n",
    "            optimizer=optimizer,\n",
    "            data_loader=train_set,\n",
    "            scheduler=scheduler,\n",
    "            device=device\n",
    "        )\n",
    "        trainer._train(num_epoch = 3, early_stopping = 2)\n",
    "        trainer.plot_data()\n",
    "\n",
    "if __name__==\"__main__\":\n",
    "    training()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
